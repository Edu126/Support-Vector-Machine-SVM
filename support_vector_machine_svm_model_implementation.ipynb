{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edu126/Support-Vector-Machine-SVM/blob/main/support_vector_machine_svm_model_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osTJkg6JqBHH"
      },
      "source": [
        "# Support Vector Machine(SVM) - Model Implementation\n",
        "**Definition**\n",
        "> Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. Its primary objective is to find a hyperplane in an N-dimensional space (where N is the number of features) that distinctly classifies the data points into different classes.\n",
        "\n",
        "> In simple terms, SVM draws the best line (hyperplane) on the ground to separate instances in a group, creating a big gap between them. Kernels, like Picasso armed with a super calculator, help SVM use interesting shapes to achieve this, making it smart in distinguishing unique features and deciding who's who.\n",
        "And Reggresion? Well, Imagine that instead of deviding your data, you want to know where the hyperplane will go and analize its trend.\n",
        "\n",
        "**About the dataset**:\n",
        "\n",
        "> The dataset contains gene expression of various leukemia patients and contains\n",
        "gene expression of various leukemia patients on 39 selected locations of the human\n",
        "genome. These genome positions refer to the genes NPM1, RUNX1, HOXA1, . . .,\n",
        "HOXA11, HOXA13. These genes are commonly known to be relevant for leukemia.\n",
        "This genomic data is the basis on which doctors obtain their diagnosis of whether a\n",
        "patient has leukemia.\n",
        "For more information refeer to the word file 'Lukemia - Data_Dictionary'\n",
        "\n",
        "This is a curated dataset so no major data transformation are required.\n",
        "\n",
        "\n",
        "**Task**:\n",
        "\n",
        "> Build an SVM classifier that decides for each patient whether or not\n",
        "they have blood cancer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Notes: No Cross validation or Hyperparameters Optimization is made for the intial porpuse of the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPbMkja8w-AU"
      },
      "source": [
        "## Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-03T16:53:19.056773Z"
        },
        "id": "l66GzS1uL9WE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Import Initial libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.max_columns', 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLOFpbWV53yR",
        "outputId": "3de07ee2-955e-4675-a45d-7c0e6c8bd3b2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Patient_ID</th>\n",
              "      <th>1563591_at</th>\n",
              "      <th>1570350_at</th>\n",
              "      <th>200063_s_at</th>\n",
              "      <th>206289_at</th>\n",
              "      <th>206847_s_at</th>\n",
              "      <th>208129_x_at</th>\n",
              "      <th>208493_at</th>\n",
              "      <th>208557_at</th>\n",
              "      <th>208604_s_at</th>\n",
              "      <th>209359_x_at</th>\n",
              "      <th>209360_s_at</th>\n",
              "      <th>209905_at</th>\n",
              "      <th>209905_at.1</th>\n",
              "      <th>210365_at</th>\n",
              "      <th>210805_x_at</th>\n",
              "      <th>211180_x_at</th>\n",
              "      <th>211181_x_at</th>\n",
              "      <th>211182_x_at</th>\n",
              "      <th>211620_x_at</th>\n",
              "      <th>213147_at</th>\n",
              "      <th>213147_at.1</th>\n",
              "      <th>213150_at</th>\n",
              "      <th>213150_at.1</th>\n",
              "      <th>213823_at</th>\n",
              "      <th>213844_at</th>\n",
              "      <th>214457_at</th>\n",
              "      <th>214639_s_at</th>\n",
              "      <th>214651_s_at</th>\n",
              "      <th>214651_s_at.1</th>\n",
              "      <th>217263_x_at</th>\n",
              "      <th>221691_x_at</th>\n",
              "      <th>221923_s_at</th>\n",
              "      <th>231786_at</th>\n",
              "      <th>235521_at</th>\n",
              "      <th>235753_at</th>\n",
              "      <th>237697_at</th>\n",
              "      <th>238571_at</th>\n",
              "      <th>238808_at</th>\n",
              "      <th>243058_at</th>\n",
              "      <th>Leukemia</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sample_1000</td>\n",
              "      <td>3.056436</td>\n",
              "      <td>3.618254</td>\n",
              "      <td>12.641006</td>\n",
              "      <td>5.062973</td>\n",
              "      <td>3.622257</td>\n",
              "      <td>5.536213</td>\n",
              "      <td>3.796584</td>\n",
              "      <td>4.578751</td>\n",
              "      <td>5.061145</td>\n",
              "      <td>5.290259</td>\n",
              "      <td>6.625408</td>\n",
              "      <td>3.943709</td>\n",
              "      <td>3.943709</td>\n",
              "      <td>5.319614</td>\n",
              "      <td>4.506269</td>\n",
              "      <td>5.983453</td>\n",
              "      <td>4.782621</td>\n",
              "      <td>4.342290</td>\n",
              "      <td>4.948362</td>\n",
              "      <td>4.679406</td>\n",
              "      <td>4.679406</td>\n",
              "      <td>3.565061</td>\n",
              "      <td>3.565061</td>\n",
              "      <td>4.519316</td>\n",
              "      <td>3.984862</td>\n",
              "      <td>3.300462</td>\n",
              "      <td>3.484044</td>\n",
              "      <td>3.482531</td>\n",
              "      <td>3.482531</td>\n",
              "      <td>3.981086</td>\n",
              "      <td>11.077904</td>\n",
              "      <td>9.686451</td>\n",
              "      <td>2.980329</td>\n",
              "      <td>3.059078</td>\n",
              "      <td>3.780181</td>\n",
              "      <td>3.873638</td>\n",
              "      <td>3.631859</td>\n",
              "      <td>3.032457</td>\n",
              "      <td>5.186670</td>\n",
              "      <td>CLL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sample_1001</td>\n",
              "      <td>2.972746</td>\n",
              "      <td>3.656448</td>\n",
              "      <td>13.009815</td>\n",
              "      <td>5.444977</td>\n",
              "      <td>4.430324</td>\n",
              "      <td>6.629713</td>\n",
              "      <td>4.143195</td>\n",
              "      <td>4.581042</td>\n",
              "      <td>4.815637</td>\n",
              "      <td>6.658555</td>\n",
              "      <td>9.108859</td>\n",
              "      <td>7.834432</td>\n",
              "      <td>7.834432</td>\n",
              "      <td>7.560836</td>\n",
              "      <td>4.993084</td>\n",
              "      <td>6.850473</td>\n",
              "      <td>5.087822</td>\n",
              "      <td>4.903638</td>\n",
              "      <td>4.579395</td>\n",
              "      <td>6.606606</td>\n",
              "      <td>6.606606</td>\n",
              "      <td>8.168509</td>\n",
              "      <td>8.168509</td>\n",
              "      <td>5.395320</td>\n",
              "      <td>7.630198</td>\n",
              "      <td>3.147876</td>\n",
              "      <td>5.237195</td>\n",
              "      <td>10.051367</td>\n",
              "      <td>10.051367</td>\n",
              "      <td>4.367952</td>\n",
              "      <td>11.784089</td>\n",
              "      <td>11.272479</td>\n",
              "      <td>3.504151</td>\n",
              "      <td>4.614741</td>\n",
              "      <td>4.456387</td>\n",
              "      <td>3.392600</td>\n",
              "      <td>3.448984</td>\n",
              "      <td>3.547128</td>\n",
              "      <td>5.084203</td>\n",
              "      <td>AML</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sample_1002</td>\n",
              "      <td>3.111013</td>\n",
              "      <td>3.910347</td>\n",
              "      <td>12.271732</td>\n",
              "      <td>6.454073</td>\n",
              "      <td>6.612310</td>\n",
              "      <td>7.080542</td>\n",
              "      <td>4.685840</td>\n",
              "      <td>5.839468</td>\n",
              "      <td>5.313898</td>\n",
              "      <td>6.910273</td>\n",
              "      <td>8.577111</td>\n",
              "      <td>9.403318</td>\n",
              "      <td>9.403318</td>\n",
              "      <td>6.119185</td>\n",
              "      <td>4.905725</td>\n",
              "      <td>7.434363</td>\n",
              "      <td>5.076497</td>\n",
              "      <td>5.192318</td>\n",
              "      <td>5.080847</td>\n",
              "      <td>8.065462</td>\n",
              "      <td>8.065462</td>\n",
              "      <td>8.535223</td>\n",
              "      <td>8.535223</td>\n",
              "      <td>5.494580</td>\n",
              "      <td>9.136387</td>\n",
              "      <td>3.765256</td>\n",
              "      <td>8.191289</td>\n",
              "      <td>11.708283</td>\n",
              "      <td>11.708283</td>\n",
              "      <td>3.875326</td>\n",
              "      <td>11.022868</td>\n",
              "      <td>10.209611</td>\n",
              "      <td>3.029066</td>\n",
              "      <td>8.911515</td>\n",
              "      <td>6.942798</td>\n",
              "      <td>3.864401</td>\n",
              "      <td>3.886512</td>\n",
              "      <td>3.015252</td>\n",
              "      <td>5.046901</td>\n",
              "      <td>AML</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sample_1003</td>\n",
              "      <td>2.882058</td>\n",
              "      <td>3.582897</td>\n",
              "      <td>12.784057</td>\n",
              "      <td>6.593272</td>\n",
              "      <td>4.799354</td>\n",
              "      <td>5.912197</td>\n",
              "      <td>3.515558</td>\n",
              "      <td>5.224020</td>\n",
              "      <td>5.401763</td>\n",
              "      <td>5.439815</td>\n",
              "      <td>9.079139</td>\n",
              "      <td>8.459776</td>\n",
              "      <td>8.459776</td>\n",
              "      <td>5.088605</td>\n",
              "      <td>4.999124</td>\n",
              "      <td>5.970327</td>\n",
              "      <td>4.814540</td>\n",
              "      <td>4.572632</td>\n",
              "      <td>4.809954</td>\n",
              "      <td>6.777287</td>\n",
              "      <td>6.777287</td>\n",
              "      <td>8.155721</td>\n",
              "      <td>8.155721</td>\n",
              "      <td>3.898220</td>\n",
              "      <td>8.122287</td>\n",
              "      <td>3.193175</td>\n",
              "      <td>3.699731</td>\n",
              "      <td>11.347153</td>\n",
              "      <td>11.347153</td>\n",
              "      <td>4.007342</td>\n",
              "      <td>11.645520</td>\n",
              "      <td>10.333872</td>\n",
              "      <td>2.632752</td>\n",
              "      <td>7.398745</td>\n",
              "      <td>5.028869</td>\n",
              "      <td>3.845556</td>\n",
              "      <td>3.326164</td>\n",
              "      <td>2.811341</td>\n",
              "      <td>4.803970</td>\n",
              "      <td>AML</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sample_1004</td>\n",
              "      <td>3.335401</td>\n",
              "      <td>3.426485</td>\n",
              "      <td>12.671934</td>\n",
              "      <td>6.060153</td>\n",
              "      <td>6.832800</td>\n",
              "      <td>6.332313</td>\n",
              "      <td>3.391523</td>\n",
              "      <td>5.938946</td>\n",
              "      <td>5.526973</td>\n",
              "      <td>6.680934</td>\n",
              "      <td>8.888095</td>\n",
              "      <td>8.965483</td>\n",
              "      <td>8.965483</td>\n",
              "      <td>6.551588</td>\n",
              "      <td>6.034367</td>\n",
              "      <td>6.700104</td>\n",
              "      <td>5.776896</td>\n",
              "      <td>5.257346</td>\n",
              "      <td>5.097954</td>\n",
              "      <td>8.174451</td>\n",
              "      <td>8.174451</td>\n",
              "      <td>9.377438</td>\n",
              "      <td>9.377438</td>\n",
              "      <td>5.407589</td>\n",
              "      <td>9.206095</td>\n",
              "      <td>3.490509</td>\n",
              "      <td>3.224430</td>\n",
              "      <td>11.609701</td>\n",
              "      <td>11.609701</td>\n",
              "      <td>4.577778</td>\n",
              "      <td>11.237164</td>\n",
              "      <td>10.486609</td>\n",
              "      <td>2.693749</td>\n",
              "      <td>8.503826</td>\n",
              "      <td>7.260643</td>\n",
              "      <td>3.547633</td>\n",
              "      <td>3.222044</td>\n",
              "      <td>2.904241</td>\n",
              "      <td>5.076562</td>\n",
              "      <td>AML</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Patient_ID  1563591_at  1570350_at  200063_s_at  206289_at  206847_s_at  \\\n",
              "0  Sample_1000    3.056436    3.618254    12.641006   5.062973     3.622257   \n",
              "1  Sample_1001    2.972746    3.656448    13.009815   5.444977     4.430324   \n",
              "2  Sample_1002    3.111013    3.910347    12.271732   6.454073     6.612310   \n",
              "3  Sample_1003    2.882058    3.582897    12.784057   6.593272     4.799354   \n",
              "4  Sample_1004    3.335401    3.426485    12.671934   6.060153     6.832800   \n",
              "\n",
              "   208129_x_at  208493_at  208557_at  208604_s_at  209359_x_at  209360_s_at  \\\n",
              "0     5.536213   3.796584   4.578751     5.061145     5.290259     6.625408   \n",
              "1     6.629713   4.143195   4.581042     4.815637     6.658555     9.108859   \n",
              "2     7.080542   4.685840   5.839468     5.313898     6.910273     8.577111   \n",
              "3     5.912197   3.515558   5.224020     5.401763     5.439815     9.079139   \n",
              "4     6.332313   3.391523   5.938946     5.526973     6.680934     8.888095   \n",
              "\n",
              "   209905_at  209905_at.1  210365_at  210805_x_at  211180_x_at  211181_x_at  \\\n",
              "0   3.943709     3.943709   5.319614     4.506269     5.983453     4.782621   \n",
              "1   7.834432     7.834432   7.560836     4.993084     6.850473     5.087822   \n",
              "2   9.403318     9.403318   6.119185     4.905725     7.434363     5.076497   \n",
              "3   8.459776     8.459776   5.088605     4.999124     5.970327     4.814540   \n",
              "4   8.965483     8.965483   6.551588     6.034367     6.700104     5.776896   \n",
              "\n",
              "   211182_x_at  211620_x_at  213147_at  213147_at.1  213150_at  213150_at.1  \\\n",
              "0     4.342290     4.948362   4.679406     4.679406   3.565061     3.565061   \n",
              "1     4.903638     4.579395   6.606606     6.606606   8.168509     8.168509   \n",
              "2     5.192318     5.080847   8.065462     8.065462   8.535223     8.535223   \n",
              "3     4.572632     4.809954   6.777287     6.777287   8.155721     8.155721   \n",
              "4     5.257346     5.097954   8.174451     8.174451   9.377438     9.377438   \n",
              "\n",
              "   213823_at  213844_at  214457_at  214639_s_at  214651_s_at  214651_s_at.1  \\\n",
              "0   4.519316   3.984862   3.300462     3.484044     3.482531       3.482531   \n",
              "1   5.395320   7.630198   3.147876     5.237195    10.051367      10.051367   \n",
              "2   5.494580   9.136387   3.765256     8.191289    11.708283      11.708283   \n",
              "3   3.898220   8.122287   3.193175     3.699731    11.347153      11.347153   \n",
              "4   5.407589   9.206095   3.490509     3.224430    11.609701      11.609701   \n",
              "\n",
              "   217263_x_at  221691_x_at  221923_s_at  231786_at  235521_at  235753_at  \\\n",
              "0     3.981086    11.077904     9.686451   2.980329   3.059078   3.780181   \n",
              "1     4.367952    11.784089    11.272479   3.504151   4.614741   4.456387   \n",
              "2     3.875326    11.022868    10.209611   3.029066   8.911515   6.942798   \n",
              "3     4.007342    11.645520    10.333872   2.632752   7.398745   5.028869   \n",
              "4     4.577778    11.237164    10.486609   2.693749   8.503826   7.260643   \n",
              "\n",
              "   237697_at  238571_at  238808_at  243058_at Leukemia  \n",
              "0   3.873638   3.631859   3.032457   5.186670      CLL  \n",
              "1   3.392600   3.448984   3.547128   5.084203      AML  \n",
              "2   3.864401   3.886512   3.015252   5.046901      AML  \n",
              "3   3.845556   3.326164   2.811341   4.803970      AML  \n",
              "4   3.547633   3.222044   2.904241   5.076562      AML  "
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Read DF\n",
        "df = pd.read_csv('leukemia.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwM4YxUs6CIj",
        "outputId": "301a7ed0-d5a6-4865-ce34-20006c2b9d18",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1273, 41)"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check the size of our df\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taNw0d5DwXpR",
        "outputId": "284ea681-8690-4b1b-d791-3257b3768a4d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1563591_at</th>\n",
              "      <th>1570350_at</th>\n",
              "      <th>200063_s_at</th>\n",
              "      <th>206289_at</th>\n",
              "      <th>206847_s_at</th>\n",
              "      <th>208129_x_at</th>\n",
              "      <th>208493_at</th>\n",
              "      <th>208557_at</th>\n",
              "      <th>208604_s_at</th>\n",
              "      <th>209359_x_at</th>\n",
              "      <th>209360_s_at</th>\n",
              "      <th>209905_at</th>\n",
              "      <th>209905_at.1</th>\n",
              "      <th>210365_at</th>\n",
              "      <th>210805_x_at</th>\n",
              "      <th>211180_x_at</th>\n",
              "      <th>211181_x_at</th>\n",
              "      <th>211182_x_at</th>\n",
              "      <th>211620_x_at</th>\n",
              "      <th>213147_at</th>\n",
              "      <th>213147_at.1</th>\n",
              "      <th>213150_at</th>\n",
              "      <th>213150_at.1</th>\n",
              "      <th>213823_at</th>\n",
              "      <th>213844_at</th>\n",
              "      <th>214457_at</th>\n",
              "      <th>214639_s_at</th>\n",
              "      <th>214651_s_at</th>\n",
              "      <th>214651_s_at.1</th>\n",
              "      <th>217263_x_at</th>\n",
              "      <th>221691_x_at</th>\n",
              "      <th>221923_s_at</th>\n",
              "      <th>231786_at</th>\n",
              "      <th>235521_at</th>\n",
              "      <th>235753_at</th>\n",
              "      <th>237697_at</th>\n",
              "      <th>238571_at</th>\n",
              "      <th>238808_at</th>\n",
              "      <th>243058_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "      <td>1273.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.115412</td>\n",
              "      <td>3.644894</td>\n",
              "      <td>12.507614</td>\n",
              "      <td>5.520219</td>\n",
              "      <td>4.133758</td>\n",
              "      <td>6.247992</td>\n",
              "      <td>3.939691</td>\n",
              "      <td>4.782672</td>\n",
              "      <td>4.970276</td>\n",
              "      <td>6.074678</td>\n",
              "      <td>8.108587</td>\n",
              "      <td>5.443801</td>\n",
              "      <td>5.443801</td>\n",
              "      <td>6.280217</td>\n",
              "      <td>5.078159</td>\n",
              "      <td>6.541487</td>\n",
              "      <td>5.142368</td>\n",
              "      <td>5.119446</td>\n",
              "      <td>5.065188</td>\n",
              "      <td>5.644310</td>\n",
              "      <td>5.644310</td>\n",
              "      <td>4.902718</td>\n",
              "      <td>4.902718</td>\n",
              "      <td>4.485124</td>\n",
              "      <td>5.445865</td>\n",
              "      <td>3.243379</td>\n",
              "      <td>4.233219</td>\n",
              "      <td>5.942459</td>\n",
              "      <td>5.942459</td>\n",
              "      <td>4.129535</td>\n",
              "      <td>11.088813</td>\n",
              "      <td>10.286677</td>\n",
              "      <td>2.924103</td>\n",
              "      <td>4.086756</td>\n",
              "      <td>4.234980</td>\n",
              "      <td>3.772124</td>\n",
              "      <td>3.684046</td>\n",
              "      <td>2.995646</td>\n",
              "      <td>5.045064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.166992</td>\n",
              "      <td>0.224113</td>\n",
              "      <td>0.343771</td>\n",
              "      <td>0.579613</td>\n",
              "      <td>1.017319</td>\n",
              "      <td>0.752175</td>\n",
              "      <td>0.485354</td>\n",
              "      <td>0.869639</td>\n",
              "      <td>0.303120</td>\n",
              "      <td>0.730567</td>\n",
              "      <td>1.145677</td>\n",
              "      <td>1.908463</td>\n",
              "      <td>1.908463</td>\n",
              "      <td>1.462943</td>\n",
              "      <td>0.808264</td>\n",
              "      <td>0.709039</td>\n",
              "      <td>0.707208</td>\n",
              "      <td>0.689390</td>\n",
              "      <td>0.536771</td>\n",
              "      <td>1.100937</td>\n",
              "      <td>1.100937</td>\n",
              "      <td>2.125653</td>\n",
              "      <td>2.125653</td>\n",
              "      <td>0.762584</td>\n",
              "      <td>2.384459</td>\n",
              "      <td>0.386378</td>\n",
              "      <td>0.899628</td>\n",
              "      <td>3.222464</td>\n",
              "      <td>3.222464</td>\n",
              "      <td>0.364682</td>\n",
              "      <td>0.523535</td>\n",
              "      <td>0.590797</td>\n",
              "      <td>0.450628</td>\n",
              "      <td>1.856661</td>\n",
              "      <td>1.155967</td>\n",
              "      <td>0.274776</td>\n",
              "      <td>0.289629</td>\n",
              "      <td>0.212019</td>\n",
              "      <td>0.294840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.662753</td>\n",
              "      <td>3.017731</td>\n",
              "      <td>9.934693</td>\n",
              "      <td>4.490391</td>\n",
              "      <td>2.963930</td>\n",
              "      <td>4.266826</td>\n",
              "      <td>3.151199</td>\n",
              "      <td>3.548252</td>\n",
              "      <td>4.105572</td>\n",
              "      <td>4.145656</td>\n",
              "      <td>4.741976</td>\n",
              "      <td>3.190132</td>\n",
              "      <td>3.190132</td>\n",
              "      <td>3.497821</td>\n",
              "      <td>3.735281</td>\n",
              "      <td>4.714119</td>\n",
              "      <td>3.536383</td>\n",
              "      <td>3.620302</td>\n",
              "      <td>3.916784</td>\n",
              "      <td>4.056136</td>\n",
              "      <td>4.056136</td>\n",
              "      <td>2.767695</td>\n",
              "      <td>2.767695</td>\n",
              "      <td>3.562991</td>\n",
              "      <td>3.144433</td>\n",
              "      <td>2.602331</td>\n",
              "      <td>2.991688</td>\n",
              "      <td>2.781264</td>\n",
              "      <td>2.781264</td>\n",
              "      <td>3.242886</td>\n",
              "      <td>6.084229</td>\n",
              "      <td>8.187756</td>\n",
              "      <td>2.563503</td>\n",
              "      <td>2.529696</td>\n",
              "      <td>2.951206</td>\n",
              "      <td>3.072127</td>\n",
              "      <td>2.861418</td>\n",
              "      <td>2.507000</td>\n",
              "      <td>4.323821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.006619</td>\n",
              "      <td>3.498312</td>\n",
              "      <td>12.376825</td>\n",
              "      <td>5.134898</td>\n",
              "      <td>3.491341</td>\n",
              "      <td>5.705982</td>\n",
              "      <td>3.663542</td>\n",
              "      <td>4.252174</td>\n",
              "      <td>4.776805</td>\n",
              "      <td>5.520393</td>\n",
              "      <td>7.293183</td>\n",
              "      <td>4.055870</td>\n",
              "      <td>4.055870</td>\n",
              "      <td>5.099879</td>\n",
              "      <td>4.489526</td>\n",
              "      <td>6.004298</td>\n",
              "      <td>4.651087</td>\n",
              "      <td>4.635643</td>\n",
              "      <td>4.745591</td>\n",
              "      <td>4.848919</td>\n",
              "      <td>4.848919</td>\n",
              "      <td>3.337838</td>\n",
              "      <td>3.337838</td>\n",
              "      <td>4.123251</td>\n",
              "      <td>3.732406</td>\n",
              "      <td>3.014873</td>\n",
              "      <td>3.610749</td>\n",
              "      <td>3.387498</td>\n",
              "      <td>3.387498</td>\n",
              "      <td>3.877556</td>\n",
              "      <td>10.853339</td>\n",
              "      <td>9.885619</td>\n",
              "      <td>2.765655</td>\n",
              "      <td>2.994094</td>\n",
              "      <td>3.516835</td>\n",
              "      <td>3.595149</td>\n",
              "      <td>3.520205</td>\n",
              "      <td>2.875824</td>\n",
              "      <td>4.848525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>3.108314</td>\n",
              "      <td>3.625279</td>\n",
              "      <td>12.564261</td>\n",
              "      <td>5.338404</td>\n",
              "      <td>3.717901</td>\n",
              "      <td>6.188445</td>\n",
              "      <td>3.837960</td>\n",
              "      <td>4.500758</td>\n",
              "      <td>4.946706</td>\n",
              "      <td>6.034923</td>\n",
              "      <td>7.929928</td>\n",
              "      <td>4.363569</td>\n",
              "      <td>4.363569</td>\n",
              "      <td>6.014045</td>\n",
              "      <td>4.877209</td>\n",
              "      <td>6.511357</td>\n",
              "      <td>4.994205</td>\n",
              "      <td>4.985503</td>\n",
              "      <td>4.948362</td>\n",
              "      <td>5.208287</td>\n",
              "      <td>5.208287</td>\n",
              "      <td>3.574624</td>\n",
              "      <td>3.574624</td>\n",
              "      <td>4.286365</td>\n",
              "      <td>4.125259</td>\n",
              "      <td>3.135998</td>\n",
              "      <td>3.910382</td>\n",
              "      <td>3.738156</td>\n",
              "      <td>3.738156</td>\n",
              "      <td>4.066445</td>\n",
              "      <td>11.110813</td>\n",
              "      <td>10.275159</td>\n",
              "      <td>2.849247</td>\n",
              "      <td>3.166868</td>\n",
              "      <td>3.732807</td>\n",
              "      <td>3.730214</td>\n",
              "      <td>3.641934</td>\n",
              "      <td>2.963258</td>\n",
              "      <td>5.001983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.204183</td>\n",
              "      <td>3.774032</td>\n",
              "      <td>12.727351</td>\n",
              "      <td>5.731433</td>\n",
              "      <td>4.327442</td>\n",
              "      <td>6.771927</td>\n",
              "      <td>4.073029</td>\n",
              "      <td>4.912413</td>\n",
              "      <td>5.134135</td>\n",
              "      <td>6.602183</td>\n",
              "      <td>8.902546</td>\n",
              "      <td>6.719136</td>\n",
              "      <td>6.719136</td>\n",
              "      <td>7.380672</td>\n",
              "      <td>5.511237</td>\n",
              "      <td>7.038619</td>\n",
              "      <td>5.516647</td>\n",
              "      <td>5.484664</td>\n",
              "      <td>5.239236</td>\n",
              "      <td>6.259974</td>\n",
              "      <td>6.259974</td>\n",
              "      <td>6.560848</td>\n",
              "      <td>6.560848</td>\n",
              "      <td>4.537772</td>\n",
              "      <td>6.721370</td>\n",
              "      <td>3.332474</td>\n",
              "      <td>4.574764</td>\n",
              "      <td>8.970728</td>\n",
              "      <td>8.970728</td>\n",
              "      <td>4.317955</td>\n",
              "      <td>11.374287</td>\n",
              "      <td>10.685750</td>\n",
              "      <td>2.947633</td>\n",
              "      <td>4.005509</td>\n",
              "      <td>4.367431</td>\n",
              "      <td>3.894196</td>\n",
              "      <td>3.770722</td>\n",
              "      <td>3.073988</td>\n",
              "      <td>5.188874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.576415</td>\n",
              "      <td>5.267596</td>\n",
              "      <td>13.196702</td>\n",
              "      <td>8.262930</td>\n",
              "      <td>8.245297</td>\n",
              "      <td>8.645966</td>\n",
              "      <td>8.595141</td>\n",
              "      <td>9.429559</td>\n",
              "      <td>6.364921</td>\n",
              "      <td>8.579970</td>\n",
              "      <td>11.321528</td>\n",
              "      <td>10.929677</td>\n",
              "      <td>10.929677</td>\n",
              "      <td>10.650974</td>\n",
              "      <td>9.022157</td>\n",
              "      <td>8.648116</td>\n",
              "      <td>9.927173</td>\n",
              "      <td>8.894274</td>\n",
              "      <td>8.470631</td>\n",
              "      <td>9.364680</td>\n",
              "      <td>9.364680</td>\n",
              "      <td>11.431219</td>\n",
              "      <td>11.431219</td>\n",
              "      <td>11.093660</td>\n",
              "      <td>12.468934</td>\n",
              "      <td>5.586510</td>\n",
              "      <td>8.191289</td>\n",
              "      <td>12.918816</td>\n",
              "      <td>12.918816</td>\n",
              "      <td>6.085998</td>\n",
              "      <td>12.569077</td>\n",
              "      <td>11.965435</td>\n",
              "      <td>8.137276</td>\n",
              "      <td>9.730069</td>\n",
              "      <td>8.558392</td>\n",
              "      <td>6.339444</td>\n",
              "      <td>6.233940</td>\n",
              "      <td>5.370392</td>\n",
              "      <td>6.803573</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        1563591_at   1570350_at  200063_s_at    206289_at  206847_s_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  1273.000000   \n",
              "mean      3.115412     3.644894    12.507614     5.520219     4.133758   \n",
              "std       0.166992     0.224113     0.343771     0.579613     1.017319   \n",
              "min       2.662753     3.017731     9.934693     4.490391     2.963930   \n",
              "25%       3.006619     3.498312    12.376825     5.134898     3.491341   \n",
              "50%       3.108314     3.625279    12.564261     5.338404     3.717901   \n",
              "75%       3.204183     3.774032    12.727351     5.731433     4.327442   \n",
              "max       4.576415     5.267596    13.196702     8.262930     8.245297   \n",
              "\n",
              "       208129_x_at    208493_at    208557_at  208604_s_at  209359_x_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  1273.000000   \n",
              "mean      6.247992     3.939691     4.782672     4.970276     6.074678   \n",
              "std       0.752175     0.485354     0.869639     0.303120     0.730567   \n",
              "min       4.266826     3.151199     3.548252     4.105572     4.145656   \n",
              "25%       5.705982     3.663542     4.252174     4.776805     5.520393   \n",
              "50%       6.188445     3.837960     4.500758     4.946706     6.034923   \n",
              "75%       6.771927     4.073029     4.912413     5.134135     6.602183   \n",
              "max       8.645966     8.595141     9.429559     6.364921     8.579970   \n",
              "\n",
              "       209360_s_at    209905_at  209905_at.1    210365_at  210805_x_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  1273.000000   \n",
              "mean      8.108587     5.443801     5.443801     6.280217     5.078159   \n",
              "std       1.145677     1.908463     1.908463     1.462943     0.808264   \n",
              "min       4.741976     3.190132     3.190132     3.497821     3.735281   \n",
              "25%       7.293183     4.055870     4.055870     5.099879     4.489526   \n",
              "50%       7.929928     4.363569     4.363569     6.014045     4.877209   \n",
              "75%       8.902546     6.719136     6.719136     7.380672     5.511237   \n",
              "max      11.321528    10.929677    10.929677    10.650974     9.022157   \n",
              "\n",
              "       211180_x_at  211181_x_at  211182_x_at  211620_x_at    213147_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  1273.000000   \n",
              "mean      6.541487     5.142368     5.119446     5.065188     5.644310   \n",
              "std       0.709039     0.707208     0.689390     0.536771     1.100937   \n",
              "min       4.714119     3.536383     3.620302     3.916784     4.056136   \n",
              "25%       6.004298     4.651087     4.635643     4.745591     4.848919   \n",
              "50%       6.511357     4.994205     4.985503     4.948362     5.208287   \n",
              "75%       7.038619     5.516647     5.484664     5.239236     6.259974   \n",
              "max       8.648116     9.927173     8.894274     8.470631     9.364680   \n",
              "\n",
              "       213147_at.1    213150_at  213150_at.1    213823_at    213844_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  1273.000000   \n",
              "mean      5.644310     4.902718     4.902718     4.485124     5.445865   \n",
              "std       1.100937     2.125653     2.125653     0.762584     2.384459   \n",
              "min       4.056136     2.767695     2.767695     3.562991     3.144433   \n",
              "25%       4.848919     3.337838     3.337838     4.123251     3.732406   \n",
              "50%       5.208287     3.574624     3.574624     4.286365     4.125259   \n",
              "75%       6.259974     6.560848     6.560848     4.537772     6.721370   \n",
              "max       9.364680    11.431219    11.431219    11.093660    12.468934   \n",
              "\n",
              "         214457_at  214639_s_at  214651_s_at  214651_s_at.1  217263_x_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000    1273.000000  1273.000000   \n",
              "mean      3.243379     4.233219     5.942459       5.942459     4.129535   \n",
              "std       0.386378     0.899628     3.222464       3.222464     0.364682   \n",
              "min       2.602331     2.991688     2.781264       2.781264     3.242886   \n",
              "25%       3.014873     3.610749     3.387498       3.387498     3.877556   \n",
              "50%       3.135998     3.910382     3.738156       3.738156     4.066445   \n",
              "75%       3.332474     4.574764     8.970728       8.970728     4.317955   \n",
              "max       5.586510     8.191289    12.918816      12.918816     6.085998   \n",
              "\n",
              "       221691_x_at  221923_s_at    231786_at    235521_at    235753_at  \\\n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  1273.000000   \n",
              "mean     11.088813    10.286677     2.924103     4.086756     4.234980   \n",
              "std       0.523535     0.590797     0.450628     1.856661     1.155967   \n",
              "min       6.084229     8.187756     2.563503     2.529696     2.951206   \n",
              "25%      10.853339     9.885619     2.765655     2.994094     3.516835   \n",
              "50%      11.110813    10.275159     2.849247     3.166868     3.732807   \n",
              "75%      11.374287    10.685750     2.947633     4.005509     4.367431   \n",
              "max      12.569077    11.965435     8.137276     9.730069     8.558392   \n",
              "\n",
              "         237697_at    238571_at    238808_at    243058_at  \n",
              "count  1273.000000  1273.000000  1273.000000  1273.000000  \n",
              "mean      3.772124     3.684046     2.995646     5.045064  \n",
              "std       0.274776     0.289629     0.212019     0.294840  \n",
              "min       3.072127     2.861418     2.507000     4.323821  \n",
              "25%       3.595149     3.520205     2.875824     4.848525  \n",
              "50%       3.730214     3.641934     2.963258     5.001983  \n",
              "75%       3.894196     3.770722     3.073988     5.188874  \n",
              "max       6.339444     6.233940     5.370392     6.803573  "
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Descriptive exploration\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cY6sQ3PQ6Znw",
        "outputId": "25f28c0c-7cce-44e2-9494-f07dfe20c8cb",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Leukemia\n",
              "AML            542\n",
              "CLL            448\n",
              "ALL            134\n",
              "CML             76\n",
              "Nonleukemia     73\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Validate classes of target variable\n",
        "df['Leukemia'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOWkXwHdUtMn"
      },
      "source": [
        "## Data Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6vEXPRc6i1O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Create a new column - transform from multiclass to binary\n",
        "df['LeukemiaClasification'] = df.Leukemia.apply(lambda x: 1 if x != 'Nonleukemia' else 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB7opCrc76h4",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x = df.drop(['Patient_ID','Leukemia','LeukemiaClasification'], axis=1) # X or explainatory variables, this is the same and we wont do any transformation\n",
        "y_bin = df['LeukemiaClasification'] # for a binary clasification (1 and 0)\n",
        "y_mc = df['Leukemia']# for a multiclass classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7uF_PFfSrKK"
      },
      "source": [
        "## Support Vector Machine Implementation\n",
        "\n",
        "The goal is to determine the leukemia class for each patient using two approaches:\n",
        "\n",
        "1. **Binary Classification:** In this approach, we assume there are only two classes: Leukemia (1) or non-Leukemia (0).\n",
        "\n",
        "2. **Multiclass Classification:** The goal is to determine to which of the classes the patient is more prone to be assigned to (AML, CLL, ALL, CML, Nonleukemia).\n",
        "\n",
        "Since the DataFrame is not very large (relative to your computing system), we'll iterate over different SVM kernels for each approach, binary and multiclass:\n",
        "\n",
        "- **Radial Basis Function (RBF) - Default:** RBF kernel is versatile and often works well in practice. It is suitable for capturing complex relationships in the data.\n",
        "\n",
        "- **Linear:** The linear kernel is computationally efficient and works well when the data is linearly separable. It is a good choice for a starting point.\n",
        "\n",
        "- **Polynomial (Poly):** The polynomial kernel is effective in capturing non-linear relationships. The degree of the polynomial can be adjusted to control the model complexity.\n",
        "\n",
        "- **Sigmoid:** The sigmoid kernel can be useful when the data distribution is not explicitly known. It is particularly suitable for neural network-like architectures.\n",
        "\n",
        "- **Precomputed:** Precomputed kernel allows you to specify a custom kernel matrix. This can be beneficial when you have prior knowledge about the relationships between data points.\n",
        "\n",
        "These kernel choices provide flexibility in capturing different types of relationships within the data, and the iteration helps identify the most suitable kernel for the leukemia classification task.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAywTbM9cO8l"
      },
      "source": [
        "### Utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VKJAmnJT-J4_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Import libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNzpi0hlTwms",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Lets define a function to perform the model iterations\n",
        "def train_evaluate_model(kernel,X_train,X_test,y_train,y_test):\n",
        "  model= SVC(kernel=kernel, random_state = 42)\n",
        "  model.fit(X_train,y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPEV17JQNh0B",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Define kernels to loop on\n",
        "kernels = ['rbf','linear','poly','sigmoid']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka1_uZxBLKtr"
      },
      "source": [
        "### Binary\n",
        "**Winner:** Poly with 96% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQS_pqI4-32K",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_bin, test_size=0.30, stratify=y_bin, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InLH8po7PH7l",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Create a dictionary to store the accuracy for each model\n",
        "bin_accuracy_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyrwoO0nWepr",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Kernel Iterations\n",
        "for kernel in kernels:\n",
        "  bin_accuracy_dict[kernel] = train_evaluate_model(kernel,X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQnAAiQdP1OC",
        "outputId": "ae6682db-3057-4c1c-c235-4dd5383203c3",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rbf</th>\n",
              "      <td>0.942408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>linear</th>\n",
              "      <td>0.955497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly</th>\n",
              "      <td>0.963351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sigmoid</th>\n",
              "      <td>0.942408</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Accuracy\n",
              "rbf      0.942408\n",
              "linear   0.955497\n",
              "poly     0.963351\n",
              "sigmoid  0.942408"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Explore models performance for binary classification\n",
        "pd.DataFrame.from_dict(bin_accuracy_dict,orient='index', columns=['Accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VffNfNn6XSGT"
      },
      "source": [
        "### Multiclass\n",
        "**Winner:** Poly with 87% accuracy\n",
        "* There might be a sligly difference if the model runs one more time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdLEBF6xYi-Y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "## Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_mc, test_size=0.30, stratify=y_mc, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6RLP0QNDYor5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Create a dictionary to store the accuracy for each model\n",
        "mc_accuracy_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri8b6CtvYqVL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Kernel Iterations\n",
        "for kernel in kernels:\n",
        "  mc_accuracy_dict[kernel] = train_evaluate_model(kernel,X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1zbwu3_YriD",
        "outputId": "bbc9fa0e-2ea3-4cf8-a64a-227185a2aeee",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rbf</th>\n",
              "      <td>0.837696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>linear</th>\n",
              "      <td>0.879581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>poly</th>\n",
              "      <td>0.876963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sigmoid</th>\n",
              "      <td>0.426702</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Accuracy\n",
              "rbf      0.837696\n",
              "linear   0.879581\n",
              "poly     0.876963\n",
              "sigmoid  0.426702"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Explore models performance for multiclass classification\n",
        "pd.DataFrame.from_dict(mc_accuracy_dict,orient='index', columns=['Accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsSiwG5YcY7S"
      },
      "source": [
        "### Model Analysis and Explainability - Multiclass\n",
        "Is goog to have great result BUT (Yes, is always good to challenge your results) what if the model is better predicting one type of leukemia than others?\n",
        "\n",
        "*As we got a good accuracy on the multiclass svm for this example we will explorar its result*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3K8eFUs5ep-_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import  classification_report\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSarBrlcdoUK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "## Train Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y_mc, test_size=0.30, stratify=y_mc, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNcoYitGdtPk",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Initialize the model\n",
        "mc_svm = SVC(kernel='poly', probability=True, degree=4, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Km4QZ5oMd8pT",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Train the model\n",
        "model = mc_svm.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOH1LLNNeSqh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Make prediction over test data\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzIZgYPwgYVt",
        "outputId": "47dd1b79-3253-4d98-db39-ceac4ac9cf65",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ALL       0.77      0.75      0.76        40\n",
            "         AML       0.90      0.89      0.90       163\n",
            "         CLL       0.93      1.00      0.96       134\n",
            "         CML       0.57      0.52      0.55        23\n",
            " Nonleukemia       0.82      0.64      0.72        22\n",
            "\n",
            "    accuracy                           0.88       382\n",
            "   macro avg       0.80      0.76      0.78       382\n",
            "weighted avg       0.87      0.88      0.87       382\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Explore the model performance for each class\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_YmCZyIjrl7"
      },
      "source": [
        "**Interpretation:**\n",
        "- The model performs well on AML, CLL, and ALL, with high precision, recall, and F1-scores.\n",
        "- CML has lower precision and recall, indicating some difficulty in correctly predicting this class.\n",
        "- Nonleukemia has lower precision and recall, suggesting challenges in distinguishing it from other classes.\n",
        "- The overall accuracy of the model is 88%, still, this is subjective and the final model performance will be evaluated based on the problem statement\n",
        "\n",
        "Last year I found this website with funny explainations of model performance metrics:\n",
        "https://www.mage.ai/blog/definitive-guide-to-accuracy-precision-recall-for-product-developers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2xKUseboby4"
      },
      "source": [
        "## **Whats next?**\n",
        "- Evaluate model feature importance\n",
        "- Perform a two step classification, here the binary result will be used as a feature in the multiclass model possibly improving the multiclass result. (This approach has some pros and cons, which I'm still reading about them.)\n",
        "- A diffrent approach can be followed to boost our model interpretability using a linear kernel and performing a OneVsRestClassifier\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "eAywTbM9cO8l",
        "Ka1_uZxBLKtr",
        "VffNfNn6XSGT",
        "qsSiwG5YcY7S"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4391869,
          "sourceId": 7541922,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4391879,
          "sourceId": 7541941,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30646,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}